{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Hussein S. Al-Olimat, hussein@knoesis.org\n",
    "\n",
    "This software is released under the GNU Affero General Public License (AGPL) v3.0 License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytest is an example usecase of using LNEx in Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordsegment\n",
    "!pip install shapely\n",
    "!pip install nltk\n",
    "!pip install elasticsearch\n",
    "!pip install elasticsearch_dsl\n",
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from shapely.geometry import MultiPoint\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"LNEx\")\n",
    "import LNEx as lnex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweets():\n",
    "    tweets_file = \"_Data/sample_tweets.txt\"\n",
    "    # read tweets from file to list\n",
    "    with open(tweets_file) as f:\n",
    "        tweets = f.read().splitlines()\n",
    "    return tweets\n",
    "\n",
    "def init_using_elasticindex(bb, cache, augmentType, dataset, capital_word_shape):\n",
    "    lnex.elasticindex(conn_string='localhost:9200', index_name=\"photon\")\n",
    "\n",
    "    geo_info = lnex.initialize( bb, augmentType=augmentType,\n",
    "                                    cache=cache,\n",
    "                                    dataset_name=dataset,\n",
    "                                    capital_word_shape=capital_word_shape)\n",
    "    return geo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbs = { \"chennai\": [12.74, 80.066986084, 13.2823848224, 80.3464508057],\n",
    "        \"louisiana\": [29.4563, -93.3453, 31.4521, -89.5276],\n",
    "        \"houston\": [29.4778611958, -95.975189209, 30.1463147381, -94.8889160156]}\n",
    "\n",
    "dataset = \"chennai\"\n",
    "\n",
    "geo_info = init_using_elasticindex(bbs[dataset], cache=False, augmentType=\"HP\", \n",
    "                                   dataset=dataset, capital_word_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for tweet in read_tweets():\n",
    "    for output in lnex.extract(tweet):\n",
    "        print(output[0], output[1], output[2], output[3][\"main\"])\n",
    "    print(\"#\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
